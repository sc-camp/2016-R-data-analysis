{
    "contents" : "# Luc Bussi√®re\n# AdvInR Nonlinear regression\n# Nov 4, 2012\n\n# last modified Nov 28, 2015\n\n\n# clear R of all objects\nrm(list=ls())\n\n\n# import the data & see columns & structure\nDECAY<-read.csv(\"decay.csv\")\nnames(DECAY)\nstr(DECAY)\n\n# check data quality\nhist(DECAY$TIME)\nhist(DECAY$MASSLEFT)\n# note distribution of response is skewed -- we'll try several approaches to modelling this and compare them\n\n# plot the raw data\npar(mfrow=c(1,1))\nplot(MASSLEFT~TIME, data=DECAY)\n\n# so a clear negative trend, but it looks curvilinear\t \n\n# let's quickly look at the diagnostics for a linear model to see what they look like\n\nMOD.LINEAR<-lm(MASSLEFT~TIME, data=DECAY)\n\npar(mfrow=c(2,3))\nplot(MOD.LINEAR)\nhist(MOD.LINEAR$residuals)\npar(mfrow=c(1,1))\n\n# note the u-shaped pattern in the first plot, which strongly suggests we need to fit a curve\n\n\n# let's first look at some transformations\npar(mfrow=c(2,2))\nhist(DECAY$MASSLEFT)\nhist(log(DECAY$MASSLEFT))\nhist(log10(DECAY$MASSLEFT))\nhist(sqrt(DECAY$MASSLEFT))\npar(mfrow=c(1,1))\n\n# By far the best looking transformation is the log transform, which makes sense because decay is an inverse exponential function in theory\n\n# create a model, with transformation\nMOD.LOG<-lm(log(MASSLEFT)~TIME,data=DECAY)\n# note that you can apply the transform in the function call\n\npar(mfrow=c(2,3))\nplot(MOD.LOG)\nhist(MOD.LOG$residuals)\npar(mfrow=c(1,1))\n\n# this is already much better, although not yet perfect\nsummary(MOD.LOG)\n\n# we can visualize the new fit to see how the model performs\n\n\nsummary(DECAY)\nNEWTIME<-seq(0,30,0.25)\n\n# to add lines I have two choices: I can either plot this on the log scale:\nNEWML<-predict(MOD.LOG,newdata=list(TIME=NEWTIME),int=\"c\")\nplot(log(MASSLEFT)~TIME, data=DECAY)\nmatlines(NEWTIME,NEWML,lty=c(1,2,2),col=\"black\")\n\n# or I can back-transform the data and plot a curve, which is more fun -- note I need to exponentiate the predicted values\nNEWML<-predict(MOD.LOG,newdata=list(TIME=NEWTIME),int=\"c\")\nplot(MASSLEFT~TIME, data=DECAY)\nmatlines(NEWTIME,exp(NEWML),lty=c(1,2,2),col=\"black\")\n\n# that's a pretty good fit, I'd say, and it's a rather simple model with only a single parameter, which is ideal\n\n##\n# Plot the original data with fitted slope and confidence interval\n#  using broom and ggplot\n##\n\nlibrary(broom)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nMOD.LOG %>%\n  augment() %>%\n  ggplot(., aes(x = TIME, y = exp(log.MASSLEFT.))) +\n  geom_point(size = 3) +\n  geom_line(aes(x = TIME, y = exp(.fitted))) +\n  geom_ribbon(aes(ymin = exp(.fitted - (1.96*.se.fit)),\n                  ymax = exp(.fitted + (1.96*.se.fit))),\n              alpha = 0.5) +\n  theme_bw() +\n  labs(x = \"Time\",\n       y = \"Mass left (g)\")\n\n################\n# can skip lines 80 to 109\n# for fun, let's see how this would work using a polynomial\n\nMOD.POLY<-lm(MASSLEFT~poly(TIME,2),data=DECAY) \n# one way to model poly, ensures orthogonal quadratic term\n\nMOD.POLY2<-lm(MASSLEFT~TIME+I(TIME^2),data=DECAY) \n# another way to model poly but less preferred b/c quad corr with x\nlibrary(car)\nvif(MOD.POLY2)\n# note high vifs, which are not present for the first model\nvif(MOD.POLY)\n\n\n\n# check diagnostics \npar(mfrow=c(2,3))\nplot(MOD.POLY)\nhist(MOD.POLY$residuals)\npar(mfrow=c(1,1))\n# some diags better, others worse than transform\n\nsummary(MOD.POLY)\n# note that there are now two parameters\n\nNEWML.POLY<-predict(MOD.POLY,newdata=list(TIME=NEWTIME),int=\"c\")\nplot(MASSLEFT~TIME, data=DECAY)\nmatlines(NEWTIME,NEWML.POLY,lty=c(1,2,2),col=\"black\")\n# the fit here is also pretty good -- in fact the R-squared is higher than for the single parameter curve, but that's not surprising\n# I think one should favour the single parameter model for two reasons: it fits theory about exponential decay (i.e., you don't get silly predictions where the material starts to increase over time towards the top the range of x), and it is more parsimonious\n\n\n# pub quality plot\nplot(MASSLEFT~TIME, data=DECAY,\n     ylab=list(\"Biomass remaining (g)\",cex=1.5),\n     xlab=list(\"Time\",cex=1.5),\n     pch=16,\n     bg=\"grey\")\nmatlines(NEWTIME,exp(NEWML),lty=c(1,2,2),col=\"black\")\n\n\n# now let's study jaw bone length as a function of age in deer\n\n# clear R of all objects\nrm(list=ls())\nDEER<-read.csv(\"jaws.csv\")\nstr(DEER)\nhead(DEER)\n\n# check data quality\nhist(DEER$AGE)\nhist(DEER$BONE)\n\n\npar(mfrow=c(2,2))\nhist(DEER$BONE)\nhist(I(DEER$BONE)^2)\nhist(sqrt(DEER$BONE))\nhist(log(DEER$BONE))\npar(mfrow=c(1,1))\n\n# not readily transformable, which shouldn't surprise us\n\nplot(DEER$AGE,DEER$BONE)\n# function looks asymptotic\n\n# for kicks, make a linear model to see how badly it fits\nMOD.LINEAR.D<-lm(BONE~AGE, data=DEER)\n\npar(mfrow=c(2,3))\nplot(MOD.LINEAR.D)\nhist(MOD.LINEAR.D$residuals)\npar(mfrow=c(1,1))\n# yuck!\n\nMOD.POLY.D<-lm(BONE~poly(AGE,2),data=DEER) \n\n\npar(mfrow=c(2,3))\nplot(MOD.POLY.D)\nhist(MOD.POLY.D$residuals)\npar(mfrow=c(1,1))\n# better but not brilliant\n\n# let's have a look anyway\nsummary(MOD.POLY.D)\n\nsummary(DEER)\n\nNEWAGE<-seq(0,51,0.5)\nNEWBONE.POLY<-predict(MOD.POLY.D,newdata=list(AGE=NEWAGE),int=\"c\")\nplot(BONE~AGE, data=DEER)\nmatlines(NEWAGE,NEWBONE.POLY,lty=c(1,2,2),col=\"black\")\n# the fit here is ok, but obviously there's a problem: do we really believe that the jaw starts to get smaller at very advanced age?\n\n# this once again highlights the need to make a realistic model -- just because the model fits doesn't mean it is biologically realistic\n\n## We can also plot in ggplot2 with a little trickery, \n##  so here's an example\nlibrary(broom)\nlibrary(ggplot2)\n\naugment(MOD.POLY.D) %>%\n  cbind(., RAW_AGE = DEER$AGE) %>%  # We need to bind our original AGE values and call them something useful\n  ggplot(., aes(x = RAW_AGE, y = BONE)) +\n  geom_point() +\n  geom_line(aes(x = RAW_AGE, y = .fitted)) +\n  geom_ribbon(aes(ymin = .fitted - (1.96*.se.fit),\n                  ymax = .fitted + (1.96*.se.fit)),\n              alpha = 0.6) +\n  theme_bw()\n\n\n# let's use nonlinear least squares to fit a more complex model formula that won't allow the line to dip at high ages\n# a function we might like to use is an asymptotic exponential of the form y = a - b * exp(-c*x), where x is the predictor, y is the response, and a,b, and c are parameters (analagous to the slope, m, and intercept, c, in y = m*x + c)\n\n# one different thing about using nonlinear least squares is that we need to provide initial guesses of the parameter values. you could use earlier studies or eyeball the graph, but for today let's use R's inbuilt \"self-starting\" exponential function SSasymp() to find candidate starting values\n\nMOD.ASYMP.SS<-nls(BONE~SSasymp(AGE,a,b,c),data=DEER)\n\n# the SSasymp part of this call tries to find good starting values\n\n# in the absence of a starter function (they don't exist for all possible model forms), you need to specify starting values yourself. For example:\nMOD.ASYMP<-nls(BONE~a-b*exp(-c*AGE),data=DEER,start=list(a=120,b=110,c=0.064))\n\n# to examine diagnostics for nls regressions we need to (install if necessary) and load nlstools\nlibrary(nlstools)\nplot(nlsResiduals(MOD.ASYMP))\n# this gives a slightly different list of diagnostic models, but it suits us fine\nplot(nlsResiduals(MOD.ASYMP.SS))\n\nsummary(MOD.ASYMP.SS)\nsummary(MOD.ASYMP)\n\n# note how different the estimates for parameter b are!\n# also note that not all starting values lead to a solution -- you can experiment with different values and see if you can generate an error where there is no solution\n\n# we should be suspicious about parameter b; it is non-significant or indistinguishable from a in the two different models.\n\n# let's try simplifying and build a two parameter model\n\nMOD.ASYMP.2<-nls(BONE~a*(1-exp(-c*AGE)),data=DEER,start=list(a=120,c=0.064))\n\nplot(nlsResiduals(MOD.ASYMP.2))\nsummary(MOD.ASYMP.2)\n\n# let's plot the two models to see how they differ\n\nNEWBONE.ASYMP<-predict(MOD.ASYMP,newdata=list(AGE=NEWAGE))\nplot(BONE~AGE, data=DEER)\nlines(NEWAGE,NEWBONE.ASYMP,col=\"black\")\n# note: matlines doesn't work with nls() I will try to find a substitute before the practical, but no guarantees....\n\n\n\nNEWBONE.ASYMP.2<-predict(MOD.ASYMP.2,newdata=list(AGE=NEWAGE))\nlines(NEWAGE,NEWBONE.ASYMP.2,col=\"red\")\n\n# the fit is virtually identical, so we should prefer the simpler model\n\nplot(BONE~AGE, data=DEER,xlab=\"Age\",ylab=\"Jawbone length (mm)\")\nlines(NEWAGE,NEWBONE.ASYMP.2,col=\"black\")\n\n# note that fitting confidence intervals around lines is tricky for curves that feature 2 or more coefficients\n\n\n# Supplementary exercise\n\n# import the data & see columns & structure\nCG<-read.csv(\"CairngormNL.csv\")\nnames(CG)\nstr(CG)\n\n# check data quality\nhist(CG$ELEVATION)\nhist(CG$PLANT.HT)\n# response var:\nhist(CG$TRANSMISSION)\n# not pretty! but looks like it won't transform easily\nhist(I(CG$TRANSMISSION)^2)\n# nope. leave alone for now\n\n# visualize relationships\nplot(TRANSMISSION~ELEVATION, data=CG)\nplot(TRANSMISSION~PLANT.HT, data=CG)\n# or\nCGSUB<-CG[,c(3:5)]\npairs(CGSUB)\n# apparent nonlinearity between elevation and both other vars; plant ht and transmission maybe linear?\n\n# start with linear model?\nMOD.LIN<-lm(TRANSMISSION~ELEVATION+PLANT.HT,data=CG)\n\npar(mfrow=c(2,3))\nplot(MOD.LIN)\nhist(MOD.LIN$residuals)\npar(mfrow=c(1,1))\n\n# one suspect record 29\n# can keep or remove as you see fit\n# i decided to bin it\nCG<-CG[-29,]\nCG\n# again\nMOD.LIN<-lm(TRANSMISSION~ELEVATION+PLANT.HT,data=CG)\n\n# check for variance inflation\nlibrary(car)\nvif(MOD.LIN)\n# fine!\n\npar(mfrow=c(2,3))\nplot(MOD.LIN)\nhist(MOD.LIN$residuals)\npar(mfrow=c(1,1))\n\nsummary(MOD.LIN)\n\n# OK but maybe nonlinearity might help\n\nMOD.POLYELEV<-lm(TRANSMISSION~poly(ELEVATION,2)*PLANT.HT,data=CG)\npar(mfrow=c(2,3))\nplot(MOD.POLYELEV)\nhist(MOD.POLYELEV$residuals)\npar(mfrow=c(1,1))\n# not obvious that this has helped yet, but have a look\n\nsummary(MOD.POLYELEV)\n# all three terms look significant, so there is nonlinearity\n# one could also fit a polynomial of plant ht, but there's no compelling evidence from the plot that it's warranted\n\nMOD.POLYELEV2<-update(MOD.POLYELEV,~.-poly(ELEVATION,2):PLANT.HT)\nanova(MOD.POLYELEV,MOD.POLYELEV2)\n# it's technically possible to take away just the interaction with the quadratic term (although it would require a bit of coding finesse), but I think this is philosophically strange, so I'm happy with removing both at once\nsummary(MOD.POLYELEV2)\n\n# it's a bit redundant for terms with only a single coefficient, but let's make sure we have a min adequate model anyway\nMOD.POLYELEV3<-update(MOD.POLYELEV2,~.-PLANT.HT)\nanova(MOD.POLYELEV3,MOD.POLYELEV2)\n\nMOD.POLYELEV4<-lm(TRANSMISSION~ELEVATION+PLANT.HT,data=CG)\n# ok, so it doesn't take THAT much finesse\nanova(MOD.POLYELEV4,MOD.POLYELEV2)\n\n# remember you can't remove the first order of a polynomial if the second order is significant, so we stop here. MOD.POLYELEV2 is min adequate model\n# check diagnostics\npar(mfrow=c(2,3))\nplot(MOD.POLYELEV2)\nhist(MOD.POLYELEV2$residuals)\npar(mfrow=c(1,1))\n# good enough\n\n# have a look again\nsummary(MOD.POLYELEV2)\n\n# pub quality plots\n# a couple of options\n# could do avPlots(), but will only produce linear version of polynomial effect\navPlots(MOD.POLYELEV2)\n# this is fine for the PLANT.HT term\navPlots(MOD.POLYELEV2,terms=\"PLANT.HT\")\n# but it's a bit trickier for the ELEVATION because it's not philosophically clear which parts of the polynomial we want to isolate from which others, and furthermore, the orthogonal nature of the quadratic term makes it hard to interpret anyway.\n# since the patterns in the raw data are the same as those from the partial effects, I think it's fine to plot the raw data. these plots will not exactly illustrate the fitted coefficients, but they may illustrate the patterns well enough. if you use this approach, you should probably note (e.g., in the legend) for readers that the graphical representation is to visualize effects (rather than to accurately represent coefficients). \n\n# for PLANT.HT\nplot(TRANSMISSION~PLANT.HT,data=CG,xlab=\"Plant height (cm)\",ylab=\"Transmission\")\n# You could enter the actual coefficients, but because you're not plotting partial effects this may look like a poorly fitting line\nabline(0.90845,-0.01274)\n\n# alternatively, just plot the univariate best fit to illustrate the pattern\nplot(TRANSMISSION~PLANT.HT,data=CG,xlab=\"Plant height (cm)\",ylab=\"Transmission\")\nabline(lm(TRANSMISSION~PLANT.HT,data=CG))\n# I wouldn't use matlines here because that would give a misleading impression of confidence -- the real confidence in the slope depends on the coefficient for ELEVATION as well\n\n\n# get coefficients from \"univariate\" polynomial regression\nUNIVAR<-lm(TRANSMISSION~poly(ELEVATION,2),data=CG)\nNEWELEV<-seq(650,1113,2)\nNEWTRANS<-predict(UNIVAR,newdata=list(ELEVATION=NEWELEV),int=\"c\")\nplot(TRANSMISSION~ELEVATION,data=CG,xlab=\"Altitude (m)\",ylab=\"Transmission\")\nmatlines(NEWELEV,NEWTRANS,lty=c(1,3,3),col=\"black\")\n\n# using {ggplot2}\nlibrary(ggplot2)\nggplot(CG, aes(x = ELEVATION, y = TRANSMISSION)) + \n  geom_point() +\n  stat_smooth(method = \"lm\", formula = y ~ x + I(x^2),se=FALSE)\n# the last argument in the last line suppresses the shaded confidence interval, which is otherwise a bit misleading\n\n# My minimal adequate model includes a significant negative effect of plant height on the index of productivity (plant height partial coefficient = -0.013 +/- 0.003; t = -3.737; P < 0.001; see figure 1) as well as a curvilinear effect of altitude that was strongly positive at low elevations but before reaching a plateau at around 900 m (linear elevation coefficient = 1.191 +/- 0.215; t = 5.543; P < 0.001; quadratic elevation coefficient = -0.606 +/- 0.221; t = -2.748; P = 0.008; see figure 2). The interaction between plant height and elevation did not significantly improve fit and was consequently removed from the final model (F(2,50) = 0.216; P = 0.807). \n\n\n\n\n\n",
    "created" : 1449223261623.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1349862937",
    "id" : "38606227",
    "lastKnownWriteTime" : 1448834808,
    "path" : "~/Documents/formations/R - Ecosse/courses/Mod_9_nonlinear_mods/AdvInR_NonlinearReg.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_source"
}